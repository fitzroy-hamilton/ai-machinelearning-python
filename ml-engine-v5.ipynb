{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engine\n",
    "\n",
    "Under GNU GPLv3 licence\n",
    "Author: Jérémy LEVENS <jeremylevens@gmail.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites - Install the SciKit-Learn dev environment\n",
    "If necessary, [a link for the installation on MacOS X](https://scikit-learn.org/stable/developers/advanced_installation.html)\n",
    "\n",
    "Environment file to import in Anaconda-Navigator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "name: sklearn-dev\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "  - anaconda-fusion\n",
    "dependencies:\n",
    "  - appnope=0.1.0=py38_1000\n",
    "  - attrs=19.3.0=py_0\n",
    "  - backcall=0.1.0=py_0\n",
    "  - binutils-meta=1.0.4=0\n",
    "  - bleach=3.1.0=py_0\n",
    "  - c-compiler=1.0.4=h1239861_0\n",
    "  - ca-certificates=2019.11.28=hecc5488_0\n",
    "  - cctools=927.0.2=h5ba7a2e_2\n",
    "  - certifi=2019.11.28=py38_0\n",
    "  - clang=9.0.0=default_hf57f61e_4\n",
    "  - clang_osx-64=9.0.0=h05bbb7f_6\n",
    "  - clangxx=9.0.0=default_hf57f61e_4\n",
    "  - clangxx_osx-64=9.0.0=h05bbb7f_6\n",
    "  - compiler-rt=9.0.0=ha700673_2\n",
    "  - compiler-rt_osx-64=9.0.0=ha700673_2\n",
    "  - compilers=1.0.4=0\n",
    "  - cxx-compiler=1.0.4=h707564b_0\n",
    "  - cycler=0.10.0=py_2\n",
    "  - cython=0.29.14=py38h4a8c4bd_0\n",
    "  - decorator=4.4.1=py_0\n",
    "  - defusedxml=0.6.0=py_0\n",
    "  - entrypoints=0.3=py38_1000\n",
    "  - fortran-compiler=1.0.4=he991be0_0\n",
    "  - freetype=2.10.0=h24853df_1\n",
    "  - gfortran_impl_osx-64=7.3.0=hf4212f2_2\n",
    "  - gfortran_osx-64=7.3.0=h22b1bf0_6\n",
    "  - gmp=6.1.2=h0a44026_1000\n",
    "  - importlib_metadata=1.3.0=py38_0\n",
    "  - ipykernel=5.1.3=py38h5ca1d4c_0\n",
    "  - ipython=7.10.2=py38h5ca1d4c_0\n",
    "  - ipython_genutils=0.2.0=py_1\n",
    "  - isl=0.19=0\n",
    "  - jedi=0.15.1=py38_0\n",
    "  - jinja2=2.10.3=py_0\n",
    "  - joblib=0.14.1=py_0\n",
    "  - jsonschema=3.2.0=py38_0\n",
    "  - jupyter_client=5.3.3=py38_1\n",
    "  - jupyter_core=4.6.1=py38_0\n",
    "  - kiwisolver=1.1.0=py38ha1b3eb9_0\n",
    "  - ld64=450.3=h3c32e8a_2\n",
    "  - libblas=3.8.0=14_openblas\n",
    "  - libcblas=3.8.0=14_openblas\n",
    "  - libcxx=9.0.0=h89e68fa_1\n",
    "  - libffi=3.2.1=h6de7cb9_1006\n",
    "  - libgfortran=4.0.0=2\n",
    "  - libiconv=1.15=h01d97ff_1005\n",
    "  - liblapack=3.8.0=14_openblas\n",
    "  - libllvm9=9.0.0=h770b8ee_3\n",
    "  - libopenblas=0.3.7=h3d69b6c_5\n",
    "  - libpng=1.6.37=h2573ce8_0\n",
    "  - libsodium=1.0.17=h01d97ff_0\n",
    "  - llvm-openmp=9.0.0=h40edb58_0\n",
    "  - markupsafe=1.1.1=py38h0b31af3_0\n",
    "  - matplotlib=3.1.2=py38_1\n",
    "  - matplotlib-base=3.1.2=py38h11da6c2_1\n",
    "  - mistune=0.8.4=py38h0b31af3_1000\n",
    "  - more-itertools=8.0.2=py_0\n",
    "  - mpc=1.1.0=h4160ff4_1006\n",
    "  - mpfr=4.0.2=h44b798e_0\n",
    "  - nbconvert=5.6.1=py38_0\n",
    "  - nbformat=4.4.0=py_1\n",
    "  - ncurses=6.1=h0a44026_1002\n",
    "  - notebook=6.0.1=py38_0\n",
    "  - numpy=1.17.3=py38hde6bac1_0\n",
    "  - openssl=1.1.1d=h0b31af3_0\n",
    "  - packaging=19.2=py_0\n",
    "  - pandas=0.25.3=py38h4f17bb1_0\n",
    "  - pandoc=2.9=0\n",
    "  - pandocfilters=1.4.2=py_1\n",
    "  - parso=0.5.2=py_0\n",
    "  - patsy=0.5.1=py_0\n",
    "  - pexpect=4.7.0=py38_0\n",
    "  - pickleshare=0.7.5=py38_1000\n",
    "  - pip=19.3.1=py38_0\n",
    "  - pluggy=0.13.1=py38_0\n",
    "  - prometheus_client=0.7.1=py_0\n",
    "  - prompt_toolkit=3.0.2=py_0\n",
    "  - ptyprocess=0.6.0=py_1001\n",
    "  - py=1.8.0=py_0\n",
    "  - pygments=2.5.2=py_0\n",
    "  - pyparsing=2.4.5=py_0\n",
    "  - pyrsistent=0.15.6=py38h0b31af3_0\n",
    "  - pytest=5.3.2=py38_0\n",
    "  - python=3.8.0=hd366da7_5\n",
    "  - python-dateutil=2.8.1=py_0\n",
    "  - pytz=2019.3=py_0\n",
    "  - pyzmq=18.1.1=py38h4bf09a9_0\n",
    "  - readline=8.0=hcfe32e1_0\n",
    "  - scikit-learn=0.22=py38h3dc85bc_1\n",
    "  - scipy=1.3.3=py38h82752d6_0\n",
    "  - seaborn=0.9.0=py_2\n",
    "  - send2trash=1.5.0=py_0\n",
    "  - setuptools=42.0.2=py38_0\n",
    "  - six=1.13.0=py38_0\n",
    "  - sqlite=3.30.1=h93121df_0\n",
    "  - statsmodels=0.10.2=py38h3b54f70_0\n",
    "  - tapi=1000.10.8=ha1b3eb9_4\n",
    "  - terminado=0.8.3=py38_0\n",
    "  - testpath=0.4.4=py_0\n",
    "  - tk=8.6.10=hbbe82c9_0\n",
    "  - tornado=6.0.3=py38h0b31af3_0\n",
    "  - traitlets=4.3.3=py38_0\n",
    "  - wcwidth=0.1.7=py_1\n",
    "  - webencodings=0.5.1=py_1\n",
    "  - wheel=0.33.6=py38_0\n",
    "  - xz=5.2.4=h1de35cc_1001\n",
    "  - zeromq=4.3.2=h6de7cb9_2\n",
    "  - zipp=0.6.0=py_0\n",
    "  - zlib=1.2.11=h0b31af3_1006\n",
    "  - et_xmlfile-1.0.1=py_1001\n",
    "  - jdcal-1.4.1=py_0\n",
    "  - openpyxl-3.0.1=py_0\n",
    "prefix: /Users/kama/.conda/envs/sklearn-dev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dependencies and checking the version of SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import __version__\n",
    "import sys, traceback\n",
    "\n",
    "required_version = \"0.22\"\n",
    "try:\n",
    "    if (__version__ < required_version):\n",
    "        raise Exception()\n",
    "except Exception:\n",
    "    print(\"***\")\n",
    "    print(\"*** /!\\\\ scikit-learn >=\", required_version, \"required while\", __version__, \"found\")\n",
    "    print(\"***\")\n",
    "    sys.exit(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and exploring Dataset\n",
    "**X** as features (independent variables) and **y** as target (dependent variable)\n",
    "\n",
    "Data are fetched from [OpenML.org](https://www.openml.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a dataset in OpenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of machine learning algorithm to use: \n",
    "```\n",
    "classification\n",
    "regression\n",
    "clustering\n",
    "dimensionality-reduction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification - Titanic dataset <span style=\"color:red\">(*to be uncommented or not*)</span>\n",
    "\n",
    "```\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "boat            Lifeboat\n",
    "body            Body Identification Number\n",
    "home.dest       Home/Destination\n",
    "\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "Fare is in Pre-1970 British Pounds (£)\n",
    " Conversion Factors:  1£ = 12s = 240d and 1s = 20d\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "sibsp:\n",
    "- Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "- Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiancées Ignored)\n",
    "\n",
    "parch:\n",
    "- Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "- Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml_source = 'titanic' # https://www.openml.org/d/40945\n",
    "openml_version = 1\n",
    "ml_type = \"classification\" \n",
    "\n",
    "export_excel = False # to put by default\n",
    "draw_pairplot = False # to put by default\n",
    "label_encode_y = True\n",
    "scoring_method = 'f1'\n",
    "\n",
    "#numeric_features = ['age', 'fare']\n",
    "#categorical_features = ['embarked', 'sex', 'pclass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification - Diabetes dataset <span style=\"color:red\">(*to be uncommented or not*)</span>\n",
    "\n",
    "```\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function\n",
    "8. Age (years)\n",
    "9. Class variable (0 or 1)\n",
    "\n",
    "Relabeled values in attribute 'class'\n",
    "    From: 0                       To: tested_negative     \n",
    "    From: 1                       To: tested_positive\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openml_source = 'diabetes' # https://www.openml.org/d/37\n",
    "#openml_version = 1\n",
    "#ml_type = \"classification\" \n",
    "\n",
    "#export_excel = False # to put by default\n",
    "#draw_pairplot = False # to put by default\n",
    "#label_encode_y = True\n",
    "#scoring_method = 'f1'\n",
    "\n",
    "#numeric_features = ['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
    "#categorical_features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification - Other datasources to be explored...\n",
    "```\n",
    "Churn : https://www.openml.org/d/40701\n",
    "Software defect prediction : https://www.openml.org/d/1068\n",
    "Breast cancer : https://www.openml.org/d/15\n",
    "Credit approval: https://www.openml.org/d/29\n",
    "Amazon employee access : https://www.openml.org/d/4135\n",
    "Click prediction : https://www.openml.org/d/1220\n",
    "Credit score : https://www.openml.org/d/461\n",
    "Adult salary : https://www.openml.org/d/1590\n",
    "Letter recognition : https://www.openml.org/d/6\n",
    "Spam base : https://www.openml.org/d/44\n",
    "Classification problem : https://www.openml.org/d/1485\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression - Stock dataset <span style=\"color:red\">(*to be uncommented or not*)</span>\n",
    "\n",
    "```\n",
    "The data provided are daily stock prices from January 1988 through October 1991, for ten aerospace companies.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openml_source = 'stock' # https://www.openml.org/d/223\n",
    "#openml_version = 1\n",
    "#ml_type = \"regression\" \n",
    "\n",
    "#export_excel = False # to put by default\n",
    "#draw_pairplot = False # to put by default\n",
    "#label_encode_y = False\n",
    "#scoring_method = 'r2'\n",
    "\n",
    "#numeric_features = ['company1', 'company2', 'company3', 'company4', 'company5', 'company6', 'company7', 'company8', 'company9']\n",
    "#categorical_features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression - Auto price dataset <span style=\"color:red\">(*to be uncommented or not*)</span>\n",
    "\n",
    "```\n",
    "This data set consists of three types of entities:\n",
    " (a) the specification of an auto in terms of various characteristics;\n",
    " (b) its assigned insurance risk rating,;\n",
    " (c) its normalized losses in use as compared to other cars. \n",
    " The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process \"symboling\". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year.\n",
    " This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year.\n",
    " - Note: Several of the attributes in the database could be used as a \"class\" attribute.\n",
    " The original data (from the UCI repository) (http://www.ics.uci.edu/~mlearn/MLSummary.html) has 205 instances\n",
    " described by 26 attributes :\n",
    " - 15 continuous\n",
    " - 1 integer\n",
    " - 10 nominal\n",
    " The following provides more information on these attributes:\n",
    " \n",
    "   1. symboling:                 -3, -2, -1, 0, 1, 2, 3.\n",
    "   2. normalized-losses:        continuous from 65 to 256.\n",
    "   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,\n",
    "                                isuzu, jaguar, mazda, mercedes-benz, mercury,\n",
    "                                mitsubishi, nissan, peugot, plymouth, porsche,\n",
    "                                renault, saab, subaru, toyota, volkswagen, volvo\n",
    "   4. fuel-type:                diesel, gas.\n",
    "   5. aspiration:               std, turbo.\n",
    "   6. num-of-doors:             four, two.\n",
    "   7. body-style:               hardtop, wagon, sedan, hatchback,convertible.\n",
    "   8. drive-wheels:             4wd, fwd, rwd.\n",
    "   9. engine-location:          front, rear.\n",
    "  10. wheel-base:               continuous from 86.6 120.9.\n",
    "  11. length:                   continuous from 141.1 to 208.1.\n",
    "  12. width:                    continuous from 60.3 to 72.3.\n",
    "  13. height:                   continuous from 47.8 to 59.8.\n",
    "  14. curb-weight:              continuous from 1488 to 4066.\n",
    "  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n",
    "  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.\n",
    "  17. engine-size:              continuous from 61 to 326.\n",
    "  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n",
    "  19. bore:                     continuous from 2.54 to 3.94.\n",
    "  20. stroke:                   continuous from 2.07 to 4.17.\n",
    "  21. compression-ratio:        continuous from 7 to 23.\n",
    "  22. horsepower:               continuous from 48 to 288.\n",
    "  23. peak-rpm:                 continuous from 4150 to 6600.\n",
    "  24. city-mpg:                 continuous from 13 to 49.\n",
    "  25. highway-mpg:              continuous from 16 to 54.\n",
    "  26. price:                    continuous from 5118 to 45400.\n",
    " \n",
    " The original data also has some missing attribute values denoted by \"?\"\n",
    "\n",
    "Target : auto price\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openml_source = 'auto_price' # https://www.openml.org/d/195\n",
    "#openml_version = 1\n",
    "#ml_type = \"regression\"\n",
    "\n",
    "#export_excel = False # to put by default\n",
    "#draw_pairplot = False # to put by default\n",
    "#label_encode_y = False\n",
    "#scoring_method = 'r2'\n",
    "\n",
    "#numeric_features = ['normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg']\n",
    "#categorical_features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression - Other datasources to be explored...\n",
    "```\n",
    "no2 : https://www.openml.org/d/547\n",
    "Vote : https://www.openml.org/d/507\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering - Customer churn <span style=\"color:red\">(*to be uncommented or not*)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openml_source = 'telco-customer-churn' # https://www.openml.org/d/42178\n",
    "#openml_version = 1\n",
    "#ml_type = \"clustering\"\n",
    "\n",
    "#export_excel = False # to put by default\n",
    "#draw_pairplot = False # to put by default\n",
    "#label_encode_y = True\n",
    "#scoring_method = 'f1'\n",
    "\n",
    "#numeric_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges']\n",
    "#categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Context\n",
    "\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]\n",
    "\n",
    "Content\n",
    "Each row represents a customer, each column contains customer's attributes described on the column Metadata.\n",
    "\n",
    "The data set includes information about:\n",
    "\n",
    "Customers who left within the last month - the column is called Churn\n",
    "Services that each customer has signed up for - phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "Customer account information - how long they've been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "Demographic info about customers - gender, age range, and if they have partners and dependents\n",
    "Inspiration\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering - Credit Card Fraud Detection <span style=\"color:red\">(*to be uncommented or not*)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openml_source = 'CreditCardFraudDetection' # https://www.openml.org/d/42175\n",
    "#openml_version = 1\n",
    "#ml_type = \"clustering\"\n",
    "\n",
    "#export_excel = False # to put by default\n",
    "#draw_pairplot = False # to put by default\n",
    "#label_encode_y = False\n",
    "#scoring_method = 'r2'\n",
    "\n",
    "#numeric_features = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12',\n",
    "#                       'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24',\n",
    "#                       'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "#categorical_features = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. \n",
    "\n",
    "Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. \n",
    "\n",
    "Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
    "\n",
    "Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. \n",
    "\n",
    "The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
    "\n",
    "Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(openml_source, version=openml_version, return_X_y=True, as_frame=True)\n",
    "\n",
    "# 'fetch_openml' can return directly 'X' and 'y' but alternatively\n",
    "# 'X' and 'y' can be obtained directly from the frame attribute:\n",
    "# X = dataset.frame.drop('survived', axis=1)\n",
    "# y = dataset.frame['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass                                             name     sex      age  \\\n",
       "0     1.0                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
       "1     1.0                   Allison, Master. Hudson Trevor    male   0.9167   \n",
       "2     1.0                     Allison, Miss. Helen Loraine  female   2.0000   \n",
       "3     1.0             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
       "4     1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
       "\n",
       "   sibsp  parch  ticket      fare    cabin embarked  boat   body  \\\n",
       "0    0.0    0.0   24160  211.3375       B5        S     2    NaN   \n",
       "1    1.0    2.0  113781  151.5500  C22 C26        S    11    NaN   \n",
       "2    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "3    1.0    2.0  113781  151.5500  C22 C26        S  None  135.0   \n",
       "4    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of features\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   pclass     1309 non-null   float64 \n",
      " 1   name       1309 non-null   object  \n",
      " 2   sex        1309 non-null   category\n",
      " 3   age        1046 non-null   float64 \n",
      " 4   sibsp      1309 non-null   float64 \n",
      " 5   parch      1309 non-null   float64 \n",
      " 6   ticket     1309 non-null   object  \n",
      " 7   fare       1308 non-null   float64 \n",
      " 8   cabin      295 non-null    object  \n",
      " 9   embarked   1307 non-null   category\n",
      " 10  boat       486 non-null    object  \n",
      " 11  body       121 non-null    float64 \n",
      " 12  home.dest  745 non-null    object  \n",
      "dtypes: category(2), float64(6), object(5)\n",
      "memory usage: 115.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: survived, dtype: category\n",
       "Categories (2, object): ['0', '1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of targets\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import math\n",
    "        \n",
    "class VisualizationHelper:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        self.dataset = pd.concat([X, y], axis=1, sort=False)\n",
    "        \n",
    "    def describe(self):\n",
    "        pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "        # percentile list \n",
    "        perc =[.10, .50, .80, .95] \n",
    "\n",
    "        # list of dtypes to include \n",
    "        include =['object', 'float', 'int', 'category', np.number, np.object] \n",
    "\n",
    "        return self.dataset.describe(percentiles = perc, include = include)\n",
    "    \n",
    "    def emptyValues(self):\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        count_missing = self.dataset.isnull().sum()\n",
    "        percent_missing = self.dataset.isnull().sum() * 100 / len(self.dataset)\n",
    "        should_drop = percent_missing >= 33\n",
    "        missing_value_df = pd.DataFrame({'count_missing': count_missing,\n",
    "                                         'percent_missing': percent_missing,\n",
    "                                         'should_drop': should_drop})\n",
    "        missing_value_df.sort_values('percent_missing', inplace=True, ascending=False)\n",
    "        print(missing_value_df)\n",
    "        \n",
    "        cmap = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "        return sns.heatmap(self.dataset.isnull(), yticklabels=False, cbar=False, cmap=cmap)\n",
    "\n",
    "    def histogram(self):\n",
    "        fig = plt.figure(figsize = (10,5), tight_layout = True)\n",
    "        ax = fig.gca()\n",
    "        \n",
    "        hist = self.dataset.hist(bins=100, grid=False, alpha=0.4, ax=ax) \n",
    "        return hist\n",
    "    \n",
    "    def distribution(self, X, y):\n",
    "        distribdataset = pd.concat([X, y], axis=1, sort=False)\n",
    "        subdistribdataset = distribdataset.select_dtypes([np.number])\n",
    "    \n",
    "        cmap = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "        sns.set(style='white')\n",
    "        sns.set_style(rc={'axes.spines.top': False, 'axes.spines.right': False, 'axes.edgecolor': 'lightgrey'})\n",
    "\n",
    "        i = 1\n",
    "        nblines = math.ceil(len(subdistribdataset.columns) / 4)\n",
    "        fig = plt.figure(figsize=(14, 6), tight_layout = True)\n",
    "        for feature in subdistribdataset:\n",
    "            plt.subplot(nblines, 4, i)\n",
    "            sns.histplot(subdistribdataset[feature], kde=True, palette=cmap)\n",
    "            i = i + 1\n",
    "    \n",
    "    def heatmap(self, mirrored = False):\n",
    "        corr = self.dataset.corr()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        colormap = sns.color_palette(\"RdBu_r\", 7)\n",
    "   \n",
    "        dropSelf = None\n",
    "        if mirrored == False:\n",
    "            # Drop self-correlations\n",
    "            dropSelf = np.zeros_like(corr)\n",
    "            dropSelf[np.triu_indices_from(dropSelf)] = True\n",
    "        \n",
    "        sns.heatmap(corr, cmap=colormap, annot=True, fmt=\".2f\", mask=dropSelf)\n",
    "        plt.show()\n",
    "    \n",
    "    def pairplot(self):\n",
    "        if ((ml_type == 'classification') or (ml_type == 'clustering')):\n",
    "            pairplot_dataset = self.dataset.fillna(method ='ffill')\n",
    "            return sns.pairplot(pairplot_dataset, vars=pairplot_dataset.select_dtypes([np.number]).columns, hue=y.name, dropna='true') \n",
    "        return None\n",
    "    \n",
    "    def export(self):\n",
    "        excel_filename = 'datasource-' + openml_source + '-v' + str(openml_version) + '.xlsx'\n",
    "        writer = pd.ExcelWriter(excel_filename)  \n",
    "\n",
    "        self.dataset.to_excel(writer)\n",
    "        writer.save()\n",
    "\n",
    "        print('DataFrame is written successfully to the Excel File:', excel_filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizationHelper = VisualizationHelper(X, y)\n",
    "visualizationHelper.distribution(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.0</td>\n",
       "      <td>1309</td>\n",
       "      <td>1309</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>1309</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>295</td>\n",
       "      <td>1307</td>\n",
       "      <td>486</td>\n",
       "      <td>121.0</td>\n",
       "      <td>745</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>nan</td>\n",
       "      <td>1307</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>929</td>\n",
       "      <td>nan</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>nan</td>\n",
       "      <td>369</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>nan</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>male</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>nan</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>13</td>\n",
       "      <td>nan</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>nan</td>\n",
       "      <td>2</td>\n",
       "      <td>843</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>11</td>\n",
       "      <td>nan</td>\n",
       "      <td>6</td>\n",
       "      <td>914</td>\n",
       "      <td>39</td>\n",
       "      <td>nan</td>\n",
       "      <td>64</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pclass                  name   sex    age  sibsp  parch    ticket  \\\n",
       "count   1309.0                  1309  1309 1046.0 1309.0 1309.0      1309   \n",
       "unique     nan                  1307     2    nan    nan    nan       929   \n",
       "top        nan  Connolly, Miss. Kate  male    nan    nan    nan  CA. 2343   \n",
       "freq       nan                     2   843    nan    nan    nan        11   \n",
       "mean       2.3                   NaN   NaN   29.9    0.5    0.4       NaN   \n",
       "std        0.8                   NaN   NaN   14.4    1.0    0.9       NaN   \n",
       "min        1.0                   NaN   NaN    0.2    0.0    0.0       NaN   \n",
       "10%        1.0                   NaN   NaN   14.0    0.0    0.0       NaN   \n",
       "50%        3.0                   NaN   NaN   28.0    0.0    0.0       NaN   \n",
       "80%        3.0                   NaN   NaN   42.0    1.0    1.0       NaN   \n",
       "95%        3.0                   NaN   NaN   57.0    2.0    2.0       NaN   \n",
       "max        3.0                   NaN   NaN   80.0    8.0    9.0       NaN   \n",
       "\n",
       "         fare        cabin embarked boat  body     home.dest survived  \n",
       "count  1308.0          295     1307  486 121.0           745     1309  \n",
       "unique    nan          186        3   27   nan           369        2  \n",
       "top       nan  C23 C25 C27        S   13   nan  New York, NY        0  \n",
       "freq      nan            6      914   39   nan            64      809  \n",
       "mean     33.3          NaN      NaN  NaN 160.8           NaN      NaN  \n",
       "std      51.8          NaN      NaN  NaN  97.7           NaN      NaN  \n",
       "min       0.0          NaN      NaN  NaN   1.0           NaN      NaN  \n",
       "10%       7.6          NaN      NaN  NaN  35.0           NaN      NaN  \n",
       "50%      14.5          NaN      NaN  NaN 155.0           NaN      NaN  \n",
       "80%      41.6          NaN      NaN  NaN 269.0           NaN      NaN  \n",
       "95%     133.7          NaN      NaN  NaN 307.0           NaN      NaN  \n",
       "max     512.3          NaN      NaN  NaN 328.0           NaN      NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizationHelper.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count_missing  percent_missing  should_drop\n",
      "body                1188             90.8         True\n",
      "cabin               1014             77.5         True\n",
      "boat                 823             62.9         True\n",
      "home.dest            564             43.1         True\n",
      "age                  263             20.1        False\n",
      "embarked               2              0.2        False\n",
      "fare                   1              0.1        False\n",
      "pclass                 0              0.0        False\n",
      "name                   0              0.0        False\n",
      "sex                    0              0.0        False\n",
      "sibsp                  0              0.0        False\n",
      "parch                  0              0.0        False\n",
      "ticket                 0              0.0        False\n",
      "survived               0              0.0        False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizationHelper.emptyValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizationHelper.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairplot (can be very slow with large dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (draw_pairplot == True):\n",
    "    visualizationHelper.pairplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to Excel (optional, can be very slow with large dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (export_excel == True):\n",
    "    visualizationHelper.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "The following steps are ordered in a *logical order* representing the order in which one should execute the transformations.\n",
    "\n",
    "#### 1. Missing values\n",
    "Handling missing values is an essential preprocessing task that can drastically deteriorate your model when not done with sufficient care. A few questions should come up when handling missing values: Do I have missing values? How are they expressed in the data? Should I withhold samples with missing values? Or should I replace them? If so, which values should they be replaced with?\n",
    "    \n",
    "Missing values can be replaced by the mean, the median or the most frequent value.\n",
    "\n",
    "Once you know a bit more about the missing data you have to decide whether or not you want to keep entries with missing data. According to Chris Albon (Machine Learning with Python Cookbook), this decision should partially depend on how random missing values are.\n",
    "\n",
    "If they are completely at random, they don’t give any extra information and can be omitted. On the other hand, if they’re not at random, the fact that a value is missing is itself information and can be expressed as an extra binary feature.\n",
    "\n",
    "Also keep in mind that deleting a whole observation because it has one missing value, might be a poor decision and lead to information loss. Just like keeping a whole row of missing values because it has a meaningful missing value might not be your best move.\n",
    "\n",
    "Before handling missing values, you need to decide if you want to use polynomial features or not. If you for example replace all the missing values by 0, all the cross-products using this feature will be 0. Moreover, if you don’t replace missing values (NaN), creating polynomial features will raise a value error in the fit_transform phase, since the input should be finite. In this respect, replacing missing values by the median or the mean seems to be a reasonable choice.\n",
    "\n",
    "```\n",
    "from sklearn.impute import SimpleImputerimp = SimpleImputer(missing_values=np.nan, strategy='mean')imp.fit_transform(X)\n",
    "```\n",
    "\n",
    "#### 2. Polynomial features\n",
    "Creating polynomial features is a simple and common way of feature engineering that adds complexity to numeric input data by combining features.\n",
    "\n",
    "Polynomial features are often created when we want to include the notion that there exists a nonlinear relationship between the features and the target.They are mostly used to add complexity to linear models with little features, or *when we suspect the effect of one feature is dependent on another feature*.\n",
    "\n",
    "Sklearn provides a PolynomialFeatures class to create polynomial features from scratch. The degree parameter determines the maximum degree of the polynomial. For example, when degree is set to two and X=x1, x2, the features created will be 1, x1, x2, x1², x1x2 and x2². The interaction_only parameter let the function know we only want the interaction features, i.e. 1, x1, x2 and x1x2.\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import PolynomialFeaturespoly = PolynomialFeatures(degree=3, interaction_only=True)polynomials = pd.DataFrame(poly.fit_transform(X), \n",
    "                           columns=['0','1','2','3', \n",
    "                                    'p1', 'p2', 'p3', 'p4'])\\\n",
    "                                        [['p1', 'p2', 'p3', 'p4']]\n",
    "```\n",
    "\n",
    "Just as with any other form of feature engineering, it is important to create polynomial features before doing any feature scaling.\n",
    "\n",
    "#### 3. Categorical features\n",
    "Munging categorical data is another essential process during data preprocessing. Unfortunately, sklearn’s machine learning library does not support handling categorical data. Even for tree-based models, it is necessary to convert categorical features to a numerical representation.\n",
    "\n",
    "Before you start transforming your data, it is important to figure out if the feature you’re working on is ordinal (as opposed to nominal). An ordinal feature is best described as a feature with natural, ordered categories and the distances between the categories is not known.\n",
    "\n",
    "Examples: sex (*nominal*), blood_type (*nominal*), educational_level (*ordinal*)\n",
    "\n",
    "Once you know what type of categorical data you’re working on, you can pick a suiting transformation tool. In sklearn that will be a OrdinalEncoder for ordinal data, and a OneHotEncoder for nominal data.\n",
    "\n",
    "Sometimes (for example after having replaced missing values) the order of our data could be not respected. This can luckily be solved by passing an ordered list of unique values for the feature to the categories parameter.\n",
    "\n",
    "```\n",
    "encoder = OrdinalEncoder(categories=['low', 'medium', 'high'])\n",
    "```\n",
    "\n",
    "Regarding nominal features, remember that we can’t replace these features by a number since this would imply the features have an order, which is untrue in case of sex or blood type.\n",
    "\n",
    "The most popular way to encode nominal features is one-hot-encoding. Essentially, each categorical feature with n categories is transformed into n binary features.\n",
    "\n",
    "Since there were no missing values in our data, it is important to have a word on how to handle missing values with the OneHotEncoder. A missing value can easily be handled as an extra feature. Note that to do this, you need to replace the missing value by an arbitrary value first (e.g. ‘missing’) If you, on the other hand, want to ignore the missing value and create an instance with all zeros (False), you can just set the handle_unkown parameter of the OneHotEncoder to ignore.\n",
    "\n",
    "#### 4. Numerical features\n",
    "Just like categorical data can be encoded, numerical features can be ‘decoded’ into categorical features. The two most common ways to do this are discretization and binarization.\n",
    "\n",
    "##### Discretization\n",
    "Discretization, also known as quantization or binning, divides a continuous feature into a pre-specified number of categories (bins), and thus makes the data discrete.\n",
    "\n",
    "One of the main goals of a discretization is to significantly reduce the number of discrete intervals of a continuous attribute. Hence, why this transformation can increase the performance of tree based models.\n",
    "\n",
    "Sklearn provides a KBinsDiscretizer class that can take care of this. The only thing you have to specify are the number of bins (n_bins) for each feature and how to encode these bins (ordinal, onehot or onehot-dense).\n",
    "\n",
    "Let’s turn to our example for some clarifications. Import the KBinsDiscretizer class and create a new instance with three bins, ordinal encoding and a uniform strategy (all bins have the same width). Then, fit and transform all our original, missing indicator and polynomial data.\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import KBinsDiscretizerdisc = KBinsDiscretizer(n_bins=3, encode='uniform', \n",
    "                        strategy='uniform')disc.fit_transform(X)\n",
    "```\n",
    "\n",
    "If the output doesn’t make sense to you, invoke the bin_edges_ attribute on the discretizer (disc) and take a look at how the bins are divided. Then try another strategy and see how the bin edges change accordingly.\n",
    "\n",
    "##### Binarization\n",
    "Feature binarization is the process of tresholding numerical features to get boolean values. Or in other words, assign a boolean value (True or False) to each sample based on a threshold. Note that binarization is an extreme form of two-bin discretization.\n",
    "\n",
    "In general binarization is useful as a feature engineering technique for creating new features that indicate something meaningful.\n",
    "\n",
    "The Binarizer class in sklearn implements binarization in a very intuitive way. The only parameters you need to specify are the threshold and copy. All values below or equal to the threshold are replaced by 0, above it by 1. If copy is set to False, inplace binarization is performed, otherwise a copy is made.\n",
    "\n",
    "#### 5. Custom transformations\n",
    "If you want to convert an existing function into a transformer to assist in data cleaning or processing, you can implement a transformer from an arbitrary function with FunctionTransformer. This class can be useful if you’re working with a Pipeline in sklearn, but can easily be replaced by applying a lambda function to the feature you want to transform (as showed below).\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "transformer.fit_transform(X.f2.values.reshape(-1, 1)) #same output\n",
    "X.f2.apply(lambda x : np.log1p(x)) #same output\n",
    "```\n",
    "\n",
    "#### 6. Feature scaling\n",
    "The next logical step in our preprocessing pipeline is to scale our features. \n",
    "\n",
    "Before applying any scaling transformations *it is very important to split your data into a train set and a test set*. If you start scaling before, your training (and test) data might end up scaled around a mean value (see below) that is not actually the mean of the train or test data, and go past the whole reason why you’re scaling in the first place.\n",
    "\n",
    "##### Standardization (e.g. Scaling)\n",
    "Standardization is a transformation that centers the data by removing the mean value of each feature and then scale it by dividing (non-constant) features by their standard deviation. After standardizing data the mean will be zero and the standard deviation one.\n",
    "\n",
    "Standardization can drastically improve the performance of models. For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n",
    "Depending on your needs and data, sklearn provides a bunch of scalers: StandardScaler, MinMaxScaler, MaxAbsScaler and RobustScaler.\n",
    "\n",
    "If your data contains many outliers, scaling using the mean and standard deviation of the data is likely to not work very well. In these cases, you can use the RobustScaler. It removes the median and scales the data according to the quantile range.\n",
    "\n",
    "#### 7. Normalization\n",
    "Normalization is the process of scaling individual samples to have unit norm. In basic terms you need to normalize data when the algorithm predicts based on the weighted relationships formed between data points. Scaling inputs to unit norms is a common operation for text classification or clustering.\n",
    "\n",
    "One of the key differences between scaling (e.g. standardizing) and normalizing, is that normalizing is a row-wise operation (every feature of a record is normalized), while scaling is a column-wise operation (every record for each feature is scaled).\n",
    "\n",
    "#### ?. Non-linear transformation\n",
    "Two types of transformations are available: quantile transforms and power transforms. Both quantile and power transforms are based on monotonic transformations of the features and thus preserve the rank of the values along each feature.\n",
    "\n",
    "Apply a power transform featurewise to make data more Gaussian-like.\n",
    "\n",
    "Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance), or other situations where normality is desired.\n",
    "\n",
    "#### ?. Feature extraction\n",
    "<span style=\"color:red\">FIXME ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\")))</span>\n",
    "\n",
    "##### Text feature extraction\n",
    "\n",
    "##### Feature hashing (FeatureHasher)\n",
    "\n",
    "##### Loading features from dicts (DictVectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up preprocessing pipeline\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html?highlight=standardscaler\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
    "\n",
    "We will train our classifier with the numeric and categorical features\n",
    "\n",
    "#### Generic preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import (\n",
    "    SimpleImputer, KNNImputer, MissingIndicator)\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, RobustScaler, MinMaxScaler, minmax_scale, OneHotEncoder,\n",
    "    MaxAbsScaler, PowerTransformer, Normalizer, KBinsDiscretizer, PolynomialFeatures)\n",
    "\n",
    "class PreprocessingPipelineHelper:\n",
    "\n",
    "    def __init__(self, X):\n",
    "#        self.numeric_features = numeric_features\n",
    "#        self.categorical_features = categorical_features\n",
    "        self.preprocessor = None\n",
    "        self.X_train_preprocessed = None\n",
    "        \n",
    "        self.integer_features = list(X.columns[X.dtypes == 'int64'])\n",
    "        self.continuous_features = list(X.columns[X.dtypes == 'float64'])\n",
    "        self.categorical_features = list(X.columns[X.dtypes == 'category'])\n",
    "        self.object_features = list(X.columns[X.dtypes == 'object'])\n",
    "        \n",
    "        print('Integer features : ', self.integer_features)\n",
    "        print('Continuous features : ', self.continuous_features)\n",
    "        print('Categorical features : ', self.categorical_features)\n",
    "        print('Object features : ', self.object_features)\n",
    "        \n",
    "        # 1. Missing values for numeric and categorical features\n",
    "        missingvalues_num_transformer = Pipeline(steps=[\n",
    "            ('missingvalues_num', SimpleImputer(strategy='median'))])\n",
    "        missingvalues_cat_transformer = Pipeline(steps=[\n",
    "            ('missingvalues_cat', SimpleImputer(strategy='constant', fill_value='missing'))])\n",
    "        \n",
    "        # 2. Polynomial features\n",
    "        polynomialfeatures_transformer = Pipeline(steps=[\n",
    "            ('polynomial_features', PolynomialFeatures(interaction_only=True))])\n",
    "\n",
    "        # 3. Categorical Features\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('categorical_transfo', OneHotEncoder(handle_unknown='ignore'))])\n",
    "        # ordinal\n",
    "\n",
    "        # 4. Numeric features (discretization, binarization)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('discretizer', KBinsDiscretizer(encode='ordinal'))])\n",
    "\n",
    "        # 5. Custom transformations\n",
    "        # FIXME\n",
    "#            ('non-linear-transfo', PowerTransformer(method='yeo-johnson', standardize=False))])\n",
    "        \n",
    "        # 6. Feature scaling (e.g. Standardization)\n",
    "        scalingnum_transformer = Pipeline(steps=[\n",
    "            ('scaler', RobustScaler())])\n",
    "        scalingcat_transformer = Pipeline(steps=[\n",
    "            ('scaler', RobustScaler(with_centering=False))])\n",
    "\n",
    "        # 7. Normalization\n",
    "        normalization_transformer = Pipeline(steps=[\n",
    "            ('normalizer', Normalizer(norm='l2'))])\n",
    "\n",
    "        # We create the full preprocessing pipeline\n",
    "        num_pipeline = Pipeline(steps=[('missingvalues_num', missingvalues_num_transformer),\n",
    "                                       ('scaler', scalingnum_transformer),\n",
    "                                       ('normalizer', normalization_transformer)])\n",
    "        cat_pipeline = Pipeline(steps=[('missingvalues_cat', missingvalues_cat_transformer),\n",
    "                                       ('categorical_transfo', categorical_transformer),\n",
    "                                       ('scaler', scalingcat_transformer),\n",
    "                                       ('normalizer', normalization_transformer)])\n",
    "#        scale_norm_pipeline = Pipeline(steps=[('scaler', scalingnum_transformer),\n",
    "#                                       ('normalizer', normalization_transformer)])\n",
    "        \n",
    "        if (len(self.categorical_features) > 0):\n",
    "            print('There are categorical features')\n",
    "            self.preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('preprocess_num', num_pipeline, self.continuous_features),\n",
    "                    ('preprocess_cat', cat_pipeline, self.categorical_features)\n",
    "#                    ('scale_norm', scale_norm_pipeline, self.continuous_features + self.categorical_features)\n",
    "                ])\n",
    "        else:\n",
    "            print('There is no categorical features')\n",
    "            self.preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('preprocess_num', num_pipeline, self.continuous_features)\n",
    "#                    ('scale_norm', scale_norm_pipeline, self.continuous_features)\n",
    "                ])\n",
    "            \n",
    "#        if (self.categorical_features != None):\n",
    "#            self.preprocessor = ColumnTransformer(\n",
    "#                transformers=[\n",
    "#                    ('num', numeric_transformer, self.numeric_features),\n",
    "#                    ('cat', categorical_transformer, self.categorical_features)])\n",
    "#        else:\n",
    "#            self.preprocessor = ColumnTransformer(\n",
    "#                transformers=[\n",
    "#                    ('num', numeric_transformer, self.numeric_features)])\n",
    "            \n",
    "    def preprocess(self, X_train, y_train):\n",
    "        # Check if there are categorical features to improve the column names\n",
    "        if (len(self.categorical_features) > 0):\n",
    "            self.X_train_preprocessed = pd.DataFrame(data=self.preprocessor.fit_transform(X_train, y_train), \n",
    "                                                columns=(self.continuous_features + self.preprocessor\\\n",
    "                                                     .transformers_[1][1].named_steps['categorical_transfo']\\\n",
    "                                                     .named_steps['categorical_transfo']\\\n",
    "                                                     .get_feature_names(self.categorical_features).tolist()))\n",
    "        else:\n",
    "            self.X_train_preprocessed = pd.DataFrame(data=self.preprocessor.fit_transform(X_train, y_train), \n",
    "                                                columns=(self.continuous_features))#self.numeric_features)\n",
    "            \n",
    "        return self.X_train_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Improve the preprocessing pipeline (FIXME TODO)</span>\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html?highlight=standardscaler#using-the-prediction-pipeline-in-a-grid-search\n",
    "\n",
    "Different imputers:\n",
    "https://scikit-learn.org/stable/auto_examples/impute/plot_missing_values.html?highlight=imputer\n",
    "\n",
    "Different scalers:\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#param_grid = {\n",
    "#    'preprocessor__num__imputer': [SimpleImputer(strategy='constant', fill_value=0),\n",
    "#                                  SimpleImputer(strategy=\"mean\"),\n",
    "#                                  SimpleImputer(strategy=\"median\"),\n",
    "#                                  KNNImputer()],\n",
    "#    'preprocessor__num__scaler': [StandardScaler(), \n",
    "#                                  MinMaxScaler(), \n",
    "#                                  MaxAbsScaler(), \n",
    "#                                  RobustScaler(quantile_range=(25, 75)), \n",
    "#                                  PowerTransformer(method='yeo-johnson'), \n",
    "#                                  Normalizer()],\n",
    "#    'classifier__C': [0.5, 1.0, 5, 10]\n",
    "#}\n",
    "#\n",
    "#grid_search = GridSearchCV(estim_grid, param_grid, verbose=1)\n",
    "#grid_search.fit(X_train, y_train)\n",
    "#\n",
    "#print((\"Best logistic regression from grid search: %.2f%%\"\n",
    "#       % (grid_search.score(X_test, y_test)*100)))\n",
    "#\n",
    "#print(\"\")\n",
    "#print(\"******************\")\n",
    "#print(\"Best estimator:\", grid_search.best_estimator_)\n",
    "#print(\"Best parameters:\", grid_search.best_params_)\n",
    "#print(\"Best score: %.2f%%\" % (grid_search.best_score_ * 100))\n",
    "#print(\"# splits: \", grid_search.n_splits_)\n",
    "#print(\"Refit time: %.0f seconds\" % grid_search.refit_time_)\n",
    "#print(\"******************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split between Train and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Dika, Mr. Mirko</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349232</td>\n",
       "      <td>7.9</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Reeves, Mr. David</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C.A. 17248</td>\n",
       "      <td>10.5</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>Brighton, Sussex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Taussig, Miss. Ruth</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110413</td>\n",
       "      <td>79.7</td>\n",
       "      <td>E68</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>nan</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Astor, Col. John Jacob</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>124.0</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Harrington, Mr. Charles H</td>\n",
       "      <td>male</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113796</td>\n",
       "      <td>42.4</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>3.0</td>\n",
       "      <td>O'Sullivan, Miss. Bridget Mary</td>\n",
       "      <td>female</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330909</td>\n",
       "      <td>7.6</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Pettersson, Miss. Ellen Natalia</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347087</td>\n",
       "      <td>7.8</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Williams, Mr. Leslie</td>\n",
       "      <td>male</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54636</td>\n",
       "      <td>16.1</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Petranec, Miss. Matilda</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349245</td>\n",
       "      <td>7.9</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass                             name     sex  age  sibsp  parch  \\\n",
       "772      3.0                  Dika, Mr. Mirko    male 17.0    0.0    0.0   \n",
       "543      2.0                Reeves, Mr. David    male 36.0    0.0    0.0   \n",
       "289      1.0              Taussig, Miss. Ruth  female 18.0    0.0    2.0   \n",
       "10       1.0           Astor, Col. John Jacob    male 47.0    1.0    0.0   \n",
       "147      1.0        Harrington, Mr. Charles H    male  nan    0.0    0.0   \n",
       "...      ...                              ...     ...  ...    ...    ...   \n",
       "1095     3.0   O'Sullivan, Miss. Bridget Mary  female  nan    0.0    0.0   \n",
       "1130     3.0  Pettersson, Miss. Ellen Natalia  female 18.0    0.0    0.0   \n",
       "1294     3.0             Williams, Mr. Leslie    male 28.5    0.0    0.0   \n",
       "860      3.0           Heikkinen, Miss. Laina  female 26.0    0.0    0.0   \n",
       "1126     3.0          Petranec, Miss. Matilda  female 28.0    0.0    0.0   \n",
       "\n",
       "                ticket  fare    cabin embarked  boat  body         home.dest  \n",
       "772             349232   7.9     None        S  None   nan              None  \n",
       "543         C.A. 17248  10.5     None        S  None   nan  Brighton, Sussex  \n",
       "289             110413  79.7      E68        S     8   nan      New York, NY  \n",
       "10            PC 17757 227.5  C62 C64        C  None 124.0      New York, NY  \n",
       "147             113796  42.4     None        S  None   nan              None  \n",
       "...                ...   ...      ...      ...   ...   ...               ...  \n",
       "1095            330909   7.6     None        Q  None   nan              None  \n",
       "1130            347087   7.8     None        S  None   nan              None  \n",
       "1294             54636  16.1     None        S  None  14.0              None  \n",
       "860   STON/O2. 3101282   7.9     None        S  None   nan              None  \n",
       "1126            349245   7.9     None        S  None   nan              None  \n",
       "\n",
       "[1047 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess *y* target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      survived\n",
       "0            0\n",
       "1            0\n",
       "2            1\n",
       "3            0\n",
       "4            0\n",
       "...        ...\n",
       "1042         0\n",
       "1043         0\n",
       "1044         0\n",
       "1045         1\n",
       "1046         0\n",
       "\n",
       "[1047 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the target value are not in number format (eg: 'yes', 'no', ...), we encode them\n",
    "if (label_encode_y == True):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_train_preprocessed = pd.DataFrame(data=le.fit_transform(y_train), columns=[y_train.name]) # np.ravel(...)\n",
    "else:\n",
    "    y_train_preprocessed = pd.DataFrame(data=y_train, columns=[y_train.name])\n",
    "    \n",
    "y_train_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess *X* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer features :  []\n",
      "Continuous features :  ['pclass', 'age', 'sibsp', 'parch', 'fare', 'body']\n",
      "Categorical features :  ['sex', 'embarked']\n",
      "Object features :  ['name', 'ticket', 'cabin', 'boat', 'home.dest']\n",
      "There are categorical features\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'male'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e7e3d7141763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreprocessor_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocessingPipelineHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_preprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_preprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_preprocessed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-2b989a3d1f21>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Check if there are categorical features to improve the column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             self.X_train_preprocessed = pd.DataFrame(data=self.preprocessor.fit_transform(X_train, y_train), \n\u001b[0m\u001b[1;32m    100\u001b[0m                                                 columns=(self.continuous_features + self.preprocessor\\\n\u001b[1;32m    101\u001b[0m                                                      \u001b[0;34m.\u001b[0m\u001b[0mtransformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_transfo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    456\u001b[0m             self._iter(fitted=fitted, replace_strings=True))\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    459\u001b[0m                 delayed(func)(\n\u001b[1;32m    460\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \"\"\"\n\u001b[1;32m    366\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 return last_step.fit(Xt, y,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# at fit, convert sparse matrices to csc for optimized computation of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;31m# the quantiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         X = self._validate_data(X, accept_sparse='csc', estimator=self,\n\u001b[0m\u001b[1;32m   1201\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                                 force_all_finite='allow-nan')\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'male'"
     ]
    }
   ],
   "source": [
    "preprocessor_helper = PreprocessingPipelineHelper(X_train)\n",
    "X_train_preprocessed = preprocessor_helper.preprocess(X_train, y_train_preprocessed)\n",
    "\n",
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizationHelper = VisualizationHelper(X_train_preprocessed, y_train_preprocessed)\n",
    "visualizationHelper.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizationHelper.emptyValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizationHelper.distribution(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizationHelper.distribution(X_train_preprocessed, y_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizationHelper.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (draw_pairplot == True):\n",
    "    visualizationHelper.pairplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization across multiple models\n",
    "### Dictionary of models and dictionary of parameters for each model\n",
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (ml_type == \"classification\"):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "    models = {\n",
    "        'LogisticRegression': LogisticRegression(max_iter=400),\n",
    "        'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "        'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "        'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "        'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "        'RandomForestClassifier': RandomForestClassifier(),\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        'SVC': SVC(),\n",
    "        'MultiLayerPerceptronClassifier': MLPClassifier()\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'LogisticRegression': [\n",
    "            { 'penalty': ['l1'], 'solver': ['liblinear', 'saga'], 'C': [1, 10, 100, 1000]},\n",
    "            { 'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], 'C': [1, 10, 100, 1000]},\n",
    "        ],\n",
    "        'KNeighborsClassifier': { 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'leaf_size': [1, 50, 100, 250, 500]},\n",
    "        'DecisionTreeClassifier': { 'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'max_features': [None, 'auto', 'sqrt', 'log2']},\n",
    "        'ExtraTreesClassifier': { 'n_estimators': [16, 32, 64] },\n",
    "        'AdaBoostClassifier':  { 'n_estimators': [16, 32, 64], 'learning_rate': [0.1, 0.5, 1.0], 'algorithm': ['SAMME', 'SAMME.R']},\n",
    "        'GradientBoostingClassifier': { 'n_estimators': [16, 32, 64], 'learning_rate': [0.1, 0.5, 1.0], 'criterion': ['friedman_mse', 'mse', 'mae']},\n",
    "        'RandomForestClassifier': { 'n_estimators': [16, 32, 64], 'criterion':  ['gini', 'entropy']},\n",
    "        'GaussianNB': {},\n",
    "        'SVC': [\n",
    "            {'kernel': ['linear'], 'C': np.logspace(0.1, 2, 3)},\n",
    "            {'kernel': ['poly'], 'C': np.logspace(0.1, 2, 3)},\n",
    "            {'kernel': ['rbf'], 'C': np.logspace(0.1, 2, 3), 'gamma': [0.001, 0.0001]},\n",
    "            {'kernel': ['sigmoid'], 'C': np.logspace(0.1, 2, 3)}\n",
    "        ],\n",
    "        'MultiLayerPerceptronClassifier': { 'solver': ['lbfgs', 'sgd', 'adam'], 'hidden_layer_sizes': [(250, 250), (300, 300)], 'tol': [0.000001, 0.00001, 0.0001, 0.001], 'max_iter': [500], 'random_state': [42] }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (ml_type == 'regression'):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'SVR': SVR(),\n",
    "        'Decision Tree': DecisionTreeRegressor(),\n",
    "        'MultiLayerPerceptronRegressor': MLPRegressor(),\n",
    "        'Lasso': Lasso(alpha=0.1),\n",
    "        'Ridge': Ridge(),\n",
    "        'ElasticNet': ElasticNet()\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        'Linear Regression': {},\n",
    "        'SVR': [\n",
    "            {'kernel': ['linear'], 'C': np.logspace(0.1, 2, 3), 'epsilon': [0.1, 1]},\n",
    "            {'kernel': ['poly'], 'C': np.logspace(0.1, 2, 3), 'degree': [2, 3, 4], 'gamma': ['scale', 'auto', 0.001, 0.0001], 'epsilon': [0.1, 1]},\n",
    "            {'kernel': ['rbf'], 'C': np.logspace(0.1, 2, 3), 'gamma': ['scale', 'auto', 0.001], 'epsilon': [0.1, 1]},\n",
    "            {'kernel': ['sigmoid'], 'C': np.logspace(0.1, 2, 3), 'gamma': ['scale', 'auto', 0.001], 'epsilon': [0.1, 1]}\n",
    "        ],\n",
    "        'Decision Tree': { 'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'], 'splitter': ['best', 'random'], 'max_features': [None, 'auto', 'sqrt', 'log2']},\n",
    "        'MultiLayerPerceptronRegressor': { 'solver': ['lbfgs', 'sgd', 'adam'], 'hidden_layer_sizes': [(250, 250), (300, 300)], 'tol': [0.000001, 0.00001, 0.0001, 0.001], 'max_iter': [500], 'random_state': [42] },\n",
    "        'Lasso': {},\n",
    "        'Ridge': { 'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], 'alpha': [0.1, 1.0, 10.0]},\n",
    "        'ElasticNet': { 'l1_ratio': [0.1, 0.5, 1.0], 'alpha': [0.1, 1.0, 10.0]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (ml_type == 'clustering'):\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.cluster import MiniBatchKMeans\n",
    "    from sklearn.cluster import MeanShift \n",
    "    from sklearn.cluster import DBSCAN\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    from sklearn.cluster import Birch\n",
    "    from sklearn import cluster #Feature Agglomeration\n",
    "    from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "    models = {\n",
    "        'K-means': KMeans(n_clusters=2),\n",
    "        'Mini Batch K-means': MiniBatchKMeans(n_clusters=2, batch_size=6),\n",
    "#        'Mean Shift': MeanShift(bandwidth=2),\n",
    "#        'DBSCAN': DBSCAN(eps=3, min_samples=2),\n",
    "#        'Agglomerative Clustering': AgglomerativeClustering(),\n",
    "#        'Birch': Birch(n_clusters=None),\n",
    "#        'Feature Agglomeration': cluster.FeatureAgglomeration(n_clusters=32),\n",
    "#        'Affinity Propagation': AffinityPropagation()\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        'K-means': {},\n",
    "        'Mini Batch K-means': {},\n",
    "#        'Mean Shift': {},\n",
    "#        'DBSCAN': {},\n",
    "#        'Agglomerative Clustering': {},\n",
    "#        'Birch': {},\n",
    "#        'Feature Agglomeration': {},\n",
    "#        'Affinity Propagation': {}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (ml_type == 'dimensionality-reduction'):\n",
    "    from sklearn.decomposition import FastICA\n",
    "    from sklearn.decomposition import IncrementalPCA\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.decomposition import KernelPCA\n",
    "    from sklearn.decomposition import SparsePCA\n",
    "    from sklearn.decomposition import NMF\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.manifold import Isomap\n",
    "    from sklearn.manifold import SpectralEmbedding\n",
    "    from sklearn.manifold import LocallyLinearEmbedding\n",
    "    \n",
    "    models = {\n",
    "        'Fast ICA': FastICA(n_components=7),\n",
    "        'Incremental PCA': IncrementalPCA(n_components=7, batch_size=200),\n",
    "        'PCA': PCA(n_components=2),\n",
    "        'Kernel PCA': KernelPCA(n_components=7, kernel='linear'),\n",
    "        'Sparse PCA': SparsePCA(n_components=5),\n",
    "        'NMF': NMF(n_components=2, init='random'),\n",
    "        'LDA': LinearDiscriminantAnalysis(n_components=2),\n",
    "        'Neighborhood Component Analysis': NeighborhoodComponentsAnalysis(n_components=2),\n",
    "        't-SNE': TSNE(n_components=2),\n",
    "        'Isomap': Isomap(n_components=2),\n",
    "        'SpectralEmbedding': SpectralEmbedding(n_components=2),\n",
    "        'LLE': LocallyLinearEmbedding(n_components=2)\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        'Fast ICA': {},\n",
    "        'Incremental PCA': {},\n",
    "        'PCA': {},\n",
    "        'Kernel PCA': {},\n",
    "        'Sparse PCA': {},\n",
    "        'NMF': {},\n",
    "        'LDA': {},\n",
    "        'Neighborhood Component Analysis': {},\n",
    "        't-SNE': {},\n",
    "        'Isomap': {},\n",
    "        'SpectralEmbedding': {},\n",
    "        'LLE': {}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the helper for Model Selection & Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class ModelSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "        self.preprocessor = None\n",
    "        \n",
    "    def fit(self, X, y, cv=3, n_jobs=-1, verbose=1, scoring=None, refit=True): # n_jobs was 3\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "                        \n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "#            print(k, \"- Best estimator:\", self.grid_searches[k].best_estimator_, \"- Best score: %.2f%%\" % (self.grid_searches[k].best_score_*100), \"- Best Params :\", self.grid_searches[k].best_params_)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        best_estimator = \"\"\n",
    "        best_score = 0\n",
    "        \n",
    "        for k in self.grid_searches:\n",
    "#            print(k, \"- Best estimator:\", \n",
    "#                  self.grid_searches[k].best_estimator_, \n",
    "#                  \"- Best score: %.2f%%\" % (self.grid_searches[k].best_score_*100), \n",
    "#                  \"- Best Params :\", self.grid_searches[k].best_params_)\n",
    "            if (self.grid_searches[k].best_score_ > best_score):\n",
    "                best_score = self.grid_searches[k].best_score_\n",
    "                best_estimator = k\n",
    "        \n",
    "        optimized_model = models[best_estimator]\n",
    "        optimized_model.set_params(**self.grid_searches[best_estimator].best_params_)\n",
    "        \n",
    "        print(\"Best model with %.2f%%\" % (best_score*100))\n",
    "#        print(optimized_model)\n",
    "        return optimized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation (model selection)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "#### Scoring - Accuracy\n",
    "Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, you have to look at other parameters to evaluate the performance of your model.\n",
    "```\n",
    "Accuracy = (TruePositive + TrueNegative) / (TruePositive + FalsePositive + FalseNegative + TrueNegative)\n",
    "```\n",
    "\n",
    "#### Scoring - Precision\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all passengers that labeled as survived, how many actually survived? High precision relates to the low false positive rate.\n",
    "```\n",
    "Precision = TruePositive / (TruePositive + FalsePositive)\n",
    "```\n",
    "\n",
    "#### Scoring - Recall (sensitivity)\n",
    "Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the passengers that truly survived, how many did we label? \n",
    "```\n",
    "Recall = TruePositive / (TruePositive + FalseNegative)\n",
    "```\n",
    "\n",
    "#### Scoring - F1 Score\n",
    "F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall.\n",
    "```\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "```\n",
    "\n",
    "#### List of *Scorers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSelectionHelper = ModelSelectionHelper(models, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSelectionHelper.fit(X_train_preprocessed, y_train_preprocessed, scoring=scoring_method, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Best parameters\n",
    "#### Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = modelSelectionHelper.score_summary(sort_by='max_score')\n",
    "mean_score = modelSelectionHelper.score_summary(sort_by='mean_score')\n",
    "mean_score.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worst 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FacetGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hexbin(x, y, color, **kwargs):\n",
    "    cmap = sns.light_palette(color, as_cmap=True)\n",
    "    plt.hexbin(x, y, gridsize=15, cmap=cmap, **kwargs)\n",
    "\n",
    "g = sns.FacetGrid(max_score, hue=\"estimator\", col=\"estimator\", col_wrap=3, height=4)\n",
    "g.map(hexbin, \"mean_score\", \"max_score\", extent=[0, 1, 0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the (best) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = modelSelectionHelper.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train_preprocessed, y_train_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (ml_type == \"classification\"):\n",
    "    from sklearn.metrics import plot_confusion_matrix\n",
    "    \n",
    "    disp = plot_confusion_matrix(best_model, X_train_preprocessed, y_train_preprocessed,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=None)\n",
    "    disp.ax_.set_title(\"Confusion matrix\")\n",
    "    print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME Visualization for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME Visualization for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME Visualization for dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the Preprocessing keeping the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME GridSearch \n",
    "#param_grid = {\n",
    "#    'preprocessor__num__imputer': [SimpleImputer(strategy='constant', fill_value=0),\n",
    "#                                  SimpleImputer(strategy=\"mean\"),\n",
    "#                                  SimpleImputer(strategy=\"median\"),\n",
    "#                                  KNNImputer()],\n",
    "#    'preprocessor__num__scaler': [StandardScaler(), \n",
    "#                                  MinMaxScaler(), \n",
    "#                                  MaxAbsScaler(), \n",
    "#                                  RobustScaler(quantile_range=(25, 75)), \n",
    "#                                  PowerTransformer(method='yeo-johnson'), \n",
    "#                                  Normalizer()],\n",
    "#    'classifier__C': [0.5, 1.0, 5, 10]\n",
    "#}\n",
    "#\n",
    "#grid_search = GridSearchCV(estim_grid, param_grid, verbose=1)\n",
    "#grid_search.fit(X_train, y_train)\n",
    "#\n",
    "#print((\"Best logistic regression from grid search: %.2f%%\"\n",
    "#       % (grid_search.score(X_test, y_test)*100)))\n",
    "#\n",
    "#print(\"\")\n",
    "#print(\"******************\")\n",
    "#print(\"Best estimator:\", grid_search.best_estimator_)\n",
    "#print(\"Best parameters:\", grid_search.best_params_)\n",
    "#print(\"Best score: %.2f%%\" % (grid_search.best_score_ * 100))\n",
    "#print(\"# splits: \", grid_search.n_splits_)\n",
    "#print(\"Refit time: %.0f seconds\" % grid_search.refit_time_)\n",
    "#print(\"******************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIXME QUESTIONS\n",
    "- Quand utiliser les différentes step du preprocesseur ? Y a-t-il des doublons de scaler / transformer ?\n",
    "- Quelles features supprimer (% de missing pour cette feature) ?\n",
    "- Quel poids de chaque feature ? https://towardsdatascience.com/machine-learning-pipelines-with-scikit-learn-d43c32a6aa52\n",
    "- Recall, Accuracy, Precision et F1\n",
    "- Training accuracy et Validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation with *Test* data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild the final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline(steps=[('preprocessor', preprocessor_helper.preprocessor),\n",
    "                           ('classifier', best_model)])\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed the best model with *test* data\n",
    "Be aware that the *test* dataset is not yet preprocessed since it happened after the dataset split. The *test* dataset preprocessing is done directly thanks to the pipeline below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy comparing the *test dataset* targets and the prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model score: %.2f%%\" % (final_pipeline.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the optimized pipeline to predict with *real* data :) <span style=\"color:red\">(*to be instanciated*)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (openml_source == 'titanic'):\n",
    "    print(\"Getting real data for Titanic dataset\")\n",
    "    \n",
    "    real_data = np.array([2.0,                        # pclass\n",
    "                 \"Jeremy LEVENS\",                     # name\n",
    "                 'male',                              # sex \n",
    "                 33,                                  # age\n",
    "                 0,                                   # sibsp\n",
    "                 2,                                   # parch\n",
    "                 '12345',                             # ticket\n",
    "                 200.5,                               # fare\n",
    "                 'E5',                                # cabin\n",
    "                 'C',                                 # embarked\n",
    "                 5,                                   # boat\n",
    "                 np.NaN,                              # body\n",
    "                 'Montreal, PQ / Chesterville, ON'])  # home.dest\n",
    "\n",
    "    cols = ['pclass', \n",
    "            'name', \n",
    "            'sex', \n",
    "            'age', \n",
    "            'sibsp', \n",
    "            'parch', \n",
    "            'ticket', \n",
    "            'fare', \n",
    "            'cabin', \n",
    "            'embarked', \n",
    "            'boat', \n",
    "            'body', \n",
    "            'home.dest']\n",
    "\n",
    "    X_real = pd.DataFrame(data=real_data.reshape(1, -1), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (openml_source == 'diabetes'):\n",
    "    print(\"Getting real data for Diabetes dataset\")\n",
    "\n",
    "    real_data = np.array([1,     # Number of times pregnant\n",
    "                         102,    # Plasma glucose concentration\n",
    "                         68,     # Diastolic blood pressure (mm Hg)\n",
    "                         47,     # Triceps skin fold thickness (mm)\n",
    "                         36,     # 2-Hour serum insulin (mu U/ml)\n",
    "                         33.83,  # Body mass index : 90kg / (1,63m x 1,63m)\n",
    "                         0.267,  # Diabetes pedigree function\n",
    "                         33      # Age (years)\n",
    "                         ])\n",
    "\n",
    "    cols = ['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
    "\n",
    "    X_real = pd.DataFrame(data=real_data.reshape(1, -1), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (openml_source == 'stock'):\n",
    "    print(\"Getting real data for Stock dataset\")\n",
    "    \n",
    "    real_data = np.array([48.9,\n",
    "                         34.2,\n",
    "                         13.6,\n",
    "                         42.6,\n",
    "                         48.1,\n",
    "                         17.1,\n",
    "                         64.1,\n",
    "                         25.0,\n",
    "                         48.6])\n",
    "    \n",
    "    # 56.62 expected pour company10 \n",
    "    cols = ['company1', 'company2', 'company3', 'company4', 'company5', 'company6', 'company7', 'company8', 'company9']\n",
    "    \n",
    "    X_real = pd.DataFrame(data=real_data.reshape(1, -1), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (openml_source == 'auto_price'):\n",
    "    print(\"Getting real data for Auto Price dataset\")\n",
    "    \n",
    "    real_data = np.array([3,\n",
    "                         186,\n",
    "                         94.5,\n",
    "                         168.9,\n",
    "                         68.3,\n",
    "                         50.2,\n",
    "                         2778,\n",
    "                         151,\n",
    "                         3.94,\n",
    "                         3.11,\n",
    "                         9.5,\n",
    "                         143,\n",
    "                         5500,\n",
    "                         19,\n",
    "                         27])\n",
    "    \n",
    "    real_data = np.array([0,\n",
    "                         91,\n",
    "                         95.7,\n",
    "                         166.3,\n",
    "                         64.4,\n",
    "                         53,\n",
    "                         2275,\n",
    "                         110,\n",
    "                         3.27,\n",
    "                         3.35,\n",
    "                         22.5,\n",
    "                         56,\n",
    "                         4500,\n",
    "                         34,\n",
    "                         36])\n",
    "    \n",
    "    # $22018 expected for the first real example \n",
    "    # $7898 expected for the second real example \n",
    "    cols = ['symboling', 'normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg']\n",
    "    \n",
    "    X_real = pd.DataFrame(data=real_data.reshape(1, -1), columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_real = final_pipeline.predict(X_real)\n",
    "\n",
    "y_pred_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
